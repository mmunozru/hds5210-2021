{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 6 Exercises\n",
    "\n",
    "_McKinney 6.1_\n",
    "\n",
    "There are multiple ways to solve the problems below.  You can use any one of several approaches.  For example, you can read CSV files using Pandas or the csv module.  Your score won't depend on which modules you choose to use unless explicitly noted below, but your programming style will still matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.1 List of Allergies\n",
    "\n",
    "In the /data directory on the Jupyter server, there is a file called `allergies.json` that contains a list of patient allergies.  It is taken from sample data provided by the EHR vendor, Epic, here: https://open.epic.com/Clinical/Allergy\n",
    "\n",
    "Take some time to look at the structure of the file.  You can open it directly in Jupyter by clicking the _Home_ icon, then the _from_instructor_ folder, and then the _data_ folder.\n",
    "\n",
    "Within the file, you'll see that it is a dictionary with many items in it.  One of those items is called `entry` and that item is a list of things.  You can tell that because the item name is immediately followed by an opening square bracket, signifying the start of a list.  It's line 11 of the file: `  \"entry\": [`\n",
    "\n",
    "Write a function named `allergy_count(json_file)` that takes as one parameter the name of the JSON file and returns an integer number of entries in that file.  Your function should open the file, read the json into a Python object, and return how many items there are in the list of `entry`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "ALLERGIES_FILE=\"/data/allergies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_count(json_file):\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    return(len(allergies.get('entry')))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(allergy_count(ALLERGIES_FILE)) == int\n",
    "assert allergy_count(ALLERGIES_FILE) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.2 Number of Patients\n",
    "\n",
    "If you dig a little bit deaper into this list of allergies, you'll see that each result has a patient associated with it.  Create a funcation called `patient_count(json_file)` that will count how many unique patients we have in this JSON structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def patient_count(json_file):\n",
    "    patients = set()\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients.add(name)\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jason Argonaut', 'Paul Boal'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.3 How Many Allergies per Patient\n",
    "\n",
    "Although each entry is a separate allergy, several of them are for the same patient.  Write a function called `allergy_per_patient(json_file)` that counts up how many allergies each patient has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_per_patient(json_file):\n",
    "    patients = {}\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients[name] = patients.setdefault(name,0) + 1\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jason Argonaut': 3, 'Paul Boal': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_per_patient(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.4 Patient Allergies and Reaction\n",
    "\n",
    "You'll see in the file that each of the items in the `entry` list have several other attributes including a patient name, substance text representation, and a reaction manifestation.  Create a function named `allergy_list(json_file)` that will create an output list that has patient name, allergy, and reaction for each `entry`.  The actual result you should get will be:\n",
    "\n",
    "```python\n",
    "[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "```\n",
    "\n",
    "You'll notice that the reaction and the manifestation of that action are lists.  You only need to capture the first reaction and the first manifestation of the action.  That is, if there is a list of things, just output the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "def allergy_list(json_file):\n",
    "    \"\"\"(json) -> list (nested list)\n",
    "    Return a list that contain the patient's name, substance they are allergic to, and \n",
    "    the allergic reaction (i.e. manifestation due to substance). A list should be created\n",
    "    for every patient in the given file. \n",
    "    \"\"\"\n",
    "    \n",
    "    reactions = []\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        patient = entry.get('resource').get('patient').get('display')\n",
    "        substance = entry.get('resource').get('substance').get('text')\n",
    "        manifestation = entry.get('resource').get('reaction')[0].get('manifestation')[0].get('text')\n",
    "        reactions.append([patient,substance,manifestation])\n",
    "    \n",
    "    return reactions\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
       " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
       " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
       " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_list(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "output=[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "\n",
    "assert allergy_list(ALLERGIES_FILE) == output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.5 Allergy Reaction\n",
    "\n",
    "Write a function called `allergy_reaction(json_file,patient,substance)` that takes three parameter and returns the reaction that will happen if the patient takes the specified substance.  Solve this, in part, by calling your `allergy_list` function inside your new `allergy_reaction` function.\n",
    "\n",
    "If the substance is not found in the allergy list, the function should return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "def allergy_reaction(json_file,patient,substance):\n",
    "    \"\"\"\n",
    "    (json,str,str) -> str\n",
    "    Return a string, which is the allergy manifestation a specific patient will experience based \n",
    "    on a specific substance they are allergic to. Check allergy information in the given json file.\n",
    "    \"\"\"\n",
    "    patient_allergies = allergy_list(json_file)\n",
    "    manifestation = None\n",
    "    \n",
    "    for entry in patient_allergies:\n",
    "        if patient in entry and substance in entry:\n",
    "            manifestation = entry[2]\n",
    "            \n",
    "    return(manifestation)\n",
    "    \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hives'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN G') == 'Hives'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS') == 'Itching'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'STRAWBERRY') == 'Anaphylaxis'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN') == None\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Paul Boal', 'PENICILLIN G') == 'Bruising'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Stretch (Extra) Problems\n",
    "\n",
    "Work on either of the stretch problems below can earn you up to 25 free points toward the midterm assignment.  That is, if you complete one of these extra problems successfully, you can skip 1 of the problems that will appear on the midterm exam coming up next week.\n",
    "\n",
    "The midterm will be distribute this Saturday 3/13.\n",
    "\n",
    "This assignment is due on Sunday 3/14.  If you are trying for one of these extra problems Slack me, and I'll provide you feedback on how you did on these before end of day Monday 3/15.  That way you can choose what to complete on the midterm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH for March 2021 - For those looking for an additional challenge\n",
    "\n",
    "As I've mentioned in class, CMS is now enforcing a rule around price transparency.  Every facility that take Medicare payments is required to publish a \"machine readable\" file with it's pricing infomration for a number of common procedures across all of the payers they work with.  There are two examples of such files in the `/data/` directory: `whiteriver.json` and `saline.xml`.\n",
    "\n",
    "If you want to compare contracted prices across these two hospitals, you'll need to read in the information from both of those files into some kind of data structure, then merge the data together from those two files.  See what you can do.\n",
    "\n",
    "See if you can create an output file that has the following fields:\n",
    "* HOSPITAL\n",
    "* PROCEDURE_CODE\n",
    "* PAYER\n",
    "* AMOUNT\n",
    "\n",
    "If you choose to work on this, you may get stuck at some point and you won't know if you're _doing it right_. Make some assumptions. Document your questions in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import & Organize White River Data: \n",
    "\n",
    "Assumption: If a payer pays $0 for a specific procedure, then they do not have a contract w/ White River. Ignore these payers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [Hospital,Code,Description,Contracts/Charge]\n",
    "#data = [str,str,str,[dict]]\n",
    "#WhiteRiver is list of 100 lists/things (i.e. possible procedures)\n",
    "#Reorganize Contracts/Charge to match Saline dataset\n",
    "\n",
    "data = []\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"/data/whiteriver.json\") as WR:\n",
    "    WRdata = json.load(WR)\n",
    "    \n",
    "    for item in WRdata.get('root')['StandardCharges']:\n",
    "        WRprocedure = [] \n",
    "        WRprocedure.append(WRdata.get('root')['HospitalorFacilityName']) #add hospital name in pos. 0\n",
    "        WRprocedure.append(item['ProcedureCode']) #add code in pos. 1\n",
    "        WRprocedure.append(item['Description'].strip()) #add name in pos. 2\n",
    "        \n",
    "        WRpayers = []\n",
    "        for entry in item:\n",
    "            if \"_\" in entry and item[entry] is not \"0\":\n",
    "                WRpayers.append({\"Payer\":entry,\"Charge\":item[entry]})  #add payers as a list of dictionaries in pos. 3\n",
    "\n",
    "        WRprocedure.append(WRpayers)\n",
    "        data.append(WRprocedure)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import, Organize, & add Saline Data to WhiteRiver: \n",
    "\n",
    "Comment for Paul: Things got difficult/inefficent in the end with the data structure I used for the object data. I couldn't figure out how to merge WhiteRiver and Saline as separate things so I just added Saline to WhiteRiver using the same data structure as WhiteRiver. \n",
    "\n",
    "It probably would have made more sense to put/keep procedure names & codes in dictionary format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [Hospital,Code,Description,Contracts/Charge]\n",
    "#data = [str,str,str,[dict]]\n",
    "#Saline has 1616 lists/things (i.e. possible procedures)\n",
    "# Add Saline to WhiteRiver; length of data should be 1717\n",
    "\n",
    "import xml.etree.ElementTree as ET #use Xpath\n",
    "\n",
    "with open(\"/data/saline.xml\") as S:\n",
    "    tree=ET.parse(S)\n",
    "    root=tree.getroot()\n",
    "    \n",
    "    hospital_name = root[0].attrib['Name']\n",
    "    \n",
    "    for element in tree.iter():\n",
    "        if element.tag == 'Item':\n",
    "            procedure_code = element.attrib['Code']\n",
    "\n",
    "        if element.tag == 'Description':\n",
    "            procedure_desc = element.text.strip()\n",
    "\n",
    "        if element.tag == 'Contracts':\n",
    "            Spayers = []\n",
    "            \n",
    "            for child in element.getchildren():\n",
    "                Spayers.append(child.attrib)\n",
    "            \n",
    "            Sprocedure = [hospital_name,procedure_code,procedure_desc,Spayers]\n",
    "            data.append(Sprocedure)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1717"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['White River Medical Center',\n",
       " '00170',\n",
       " 'ANESTH PROCEDURE ON MOUTH',\n",
       " [{'Payer': 'AETNA_Outpatient', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'AETNA_EmergencyRoom', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'AETNAOTHER_Outpatient', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'AETNAOTHER_EmergencyRoom', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'QUALCHOICE_Outpatient', 'Charge': '5346.0848'},\n",
       "  {'Payer': 'QUALCHOICE_EmergencyRoom', 'Charge': '5346.0848'},\n",
       "  {'Payer': 'WEBTPAAetnaNonemployee_Outpatient', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'WEBTPAAetnaNonemployee_EmergencyRoom', 'Charge': '8400.9904'}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on json & xml file structures (Ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to identify part of a key with different dictionary structures:\n",
    "\n",
    "# WR_test={\"GrossCharge\":\"1000\",\"Cash\":\"50\",\"cigna_OPPS\":\"100\",\"Cigna_Outpatient\":\"300\",\"Aetna_OPPS\":\"0\",\"Allwell_EmergencyRoom\":\"0\"}\n",
    "\n",
    "# payers=[]\n",
    "\n",
    "# for entry in WR_test:\n",
    "#     if \"_\" in entry and WR_test[entry] is not \"0\":\n",
    "#         payers.append({\"Payer\":entry,\"Charge\":WR_test[entry]})\n",
    "\n",
    "\n",
    "#test=[{\"GrossCharge\":\"1000\"},{\"Cash\":\"50\"},{\"cigna_OPPS\":\"100\"},{\"Cigna_Outpatient\":\"300\"},{\"Aetna_OPPS\":\"0\"},{\"Allwell_EmergencyRoom\":\"0\"}]\n",
    "\n",
    "#test_list=[]\n",
    "\n",
    "#for entry in test:\n",
    "    #for item in entry.keys():\n",
    "        #if \"_\" in item:\n",
    "            #test_list.append(entry)\n",
    "            \n",
    "            \n",
    "# Working w/ XML file:\n",
    "\n",
    "#for description in root.iter('Description'):  #loops through all Description \n",
    "    #print(description.text) #provides text outside of tag \n",
    "    \n",
    "#tree.findall('.//Contract') #gives all instances of Contract element- use len if needed\n",
    "#for element in tree.findall('.//Contract') :\n",
    "    #print(element.attrib) #provides attribute inside tag (i.e. thing associated w/ contract)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create function w/ procedure code, name, & data as inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not super efficient/pretty to loop through the object data\n",
    "#Probably should have used dict to quickly search for code/name function input\n",
    "\n",
    "def payer_cost(code,data,name = ''):\n",
    "    \"\"\"\n",
    "    (str,list,str) -> list\n",
    "    Return procedure information (code, name) and negotiated payer prices for \n",
    "    procedures done at White River Medical Center and Saline Memorial Hospital. \n",
    "    \"\"\"\n",
    "    \n",
    "    index = []\n",
    "\n",
    "    for cnt,item in enumerate(data):\n",
    "        if code == item[1] or name == item[2]:\n",
    "            index.append(cnt)\n",
    "\n",
    "    if len(index) == 1:\n",
    "        msg = data[index[0]]\n",
    "        return(msg)\n",
    "        \n",
    "    else:\n",
    "        msg1 = data[index[0]]\n",
    "        msg2 = data[index[1]]\n",
    "        return(msg1,msg2)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['White River Medical Center',\n",
       " '00170',\n",
       " 'ANESTH PROCEDURE ON MOUTH',\n",
       " [{'Payer': 'AETNA_Outpatient', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'AETNA_EmergencyRoom', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'AETNAOTHER_Outpatient', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'AETNAOTHER_EmergencyRoom', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'QUALCHOICE_Outpatient', 'Charge': '5346.0848'},\n",
       "  {'Payer': 'QUALCHOICE_EmergencyRoom', 'Charge': '5346.0848'},\n",
       "  {'Payer': 'WEBTPAAetnaNonemployee_Outpatient', 'Charge': '8400.9904'},\n",
       "  {'Payer': 'WEBTPAAetnaNonemployee_EmergencyRoom', 'Charge': '8400.9904'}]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payer_cost('00170',data) #only one hospital has code\n",
    "#payer_cost('11010',data)  #both hospitals have this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH from March 2020 - For those looking for an additional challenge\n",
    "\n",
    "The Coronavirus is creating quite the stir right now.  There are some sources suggesting that trends show it is going to be significantly more serious than SARS was back in the 2002 timeframe.  Here's one visualization trying to demonstrate that: https://www.reddit.com/r/China_Flu/comments/ev2b4v/i_updated_some_charts_comparing_this_outbreak/\n",
    "\n",
    "Someone on Kaggle has generously already compiled a dataset based on information from Johns Hopkins about the Coronavirus outbreak.  https://www.kaggle.com/brendaso/2019-coronavirus-dataset-01212020-01262020  Create a Kaggle account, if you don't already have one.  Download this data set and then upload it to your Jupyter Home folder.  (The \"up arrow\" button is for uploading a file.)\n",
    "\n",
    "Use Python's built-in `csv` module to read the data from this file and generate the following information: **what are the total confirmed cases in all of Mainland China as of the latest information in the data set?**  Some important things to note:\n",
    "* Each entry for a given city has the **cumulative** number of cases.  So that column is not additive (it cannot be summed).  You'll have to find a way to filter your data for the last day for each city, then total those up.\n",
    "* If you choose to parse the date column, you will want to lookup how to do that using Python's `datetime` module.  Especially the `strptime` function.  https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior  Hint: you can parse a date string in the format 2/17/2020 using the code below.  This link will tell you what things like `%m` and `%Y` mean.\n",
    "\n",
    "```\n",
    "from datetime import datetime\n",
    "d = datetime.strptime('2/17/2020', '%m/%d/%Y')\n",
    "```\n",
    "\n",
    "If you want to take this another step, **create a list of tuples that contain (observate date, total confirmed) totalled over all locations represented in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Save this note with Ctrl-S (or Cmd-S)\n",
    "2. Skip down to the last command cell (the one starting with `%%bash`) and run that cell.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DO NOT REMOVE THIS LINE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cef8011cb395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DO NOT REMOVE THIS LINE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: DO NOT REMOVE THIS LINE"
     ]
    }
   ],
   "source": [
    "assert False, \"DO NOT REMOVE THIS LINE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "[main 20281f5] Submitting the week 6 programming assignment\n",
      " 2 files changed, 821 insertions(+), 3 deletions(-)\n",
      " create mode 100644 week06/week06_assignment_2.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:mmunozru/hds5210-2021.git\n",
      "   21266e2..20281f5  main -> main\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git pull\n",
    "git add week06_assignment_2.ipynb\n",
    "git commit -a -m \"Submitting the week 6 programming assignment\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "If the message above says something like _Submitting the week 6 programming assignment_ or _Everything is up to date_, then your work was submitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
